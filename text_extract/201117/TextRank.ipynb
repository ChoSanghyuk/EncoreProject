{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>id</th>\n",
       "      <th>article_original</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>extractive</th>\n",
       "      <th>extracted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>당진시대</td>\n",
       "      <td>327827480</td>\n",
       "      <td>당진시 문화관광과를 대상으로 하는 행정사무감사에서 당진시립합창단 관계자가 보낸 것으...</td>\n",
       "      <td>지난 6일 당진시의회 행정사무감사에서 '합창단이 소리를 작게 낼 것이니 알고 있으라...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>당진시 문화관광과를 대상으로 하는 행정사무감사에서 당진시립합창단 관계자가 보낸 것으...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>국제신문</td>\n",
       "      <td>339840364</td>\n",
       "      <td>미국 메이저리그(MLB)에서 활동하는 한국 선수들의 시즌 초반 희비가 엇갈리고 있다...</td>\n",
       "      <td>LA 에인절스의 최지만이 맹활약을 하여 시즌 타율 0.250에서 0.313으로 올리...</td>\n",
       "      <td>[0, 1, 3]</td>\n",
       "      <td>미국 메이저리그(MLB)에서 활동하는 한국 선수들의 시즌 초반 희비가 엇갈리고 있다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>기호일보</td>\n",
       "      <td>371071597</td>\n",
       "      <td>인천 부영공원 운영 생활야구협회 80여 동호회 팀에 260만 원씩 받아\\n국유지로 ...</td>\n",
       "      <td>16일 부평구와 협회 등에 따르면 부영공원 안에 있는 야구장을 구생활체육야구협회가 ...</td>\n",
       "      <td>[6, 7, 10]</td>\n",
       "      <td>16일 부평구와 협회 등에 따르면 부영공원 안에 있는 야구장을 구생활체육야구협회가 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  media         id                                   article_original  \\\n",
       "0  당진시대  327827480  당진시 문화관광과를 대상으로 하는 행정사무감사에서 당진시립합창단 관계자가 보낸 것으...   \n",
       "1  국제신문  339840364  미국 메이저리그(MLB)에서 활동하는 한국 선수들의 시즌 초반 희비가 엇갈리고 있다...   \n",
       "2  기호일보  371071597  인천 부영공원 운영 생활야구협회 80여 동호회 팀에 260만 원씩 받아\\n국유지로 ...   \n",
       "\n",
       "                                         abstractive  extractive  \\\n",
       "0  지난 6일 당진시의회 행정사무감사에서 '합창단이 소리를 작게 낼 것이니 알고 있으라...   [0, 1, 2]   \n",
       "1  LA 에인절스의 최지만이 맹활약을 하여 시즌 타율 0.250에서 0.313으로 올리...   [0, 1, 3]   \n",
       "2  16일 부평구와 협회 등에 따르면 부영공원 안에 있는 야구장을 구생활체육야구협회가 ...  [6, 7, 10]   \n",
       "\n",
       "                                           extracted  \n",
       "0  당진시 문화관광과를 대상으로 하는 행정사무감사에서 당진시립합창단 관계자가 보낸 것으...  \n",
       "1  미국 메이저리그(MLB)에서 활동하는 한국 선수들의 시즌 초반 희비가 엇갈리고 있다...  \n",
       "2  16일 부평구와 협회 등에 따르면 부영공원 안에 있는 야구장을 구생활체육야구협회가 ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_vocabulary(sents, tokenize, min_count=2):\n",
    "    counter = Counter(w for sent in sents for w in tokenize(sent))\n",
    "    counter = {w:c for w,c in counter.items() if c >= min_count}\n",
    "    idx_to_vocab = [w for w, _ in sorted(counter.items(), key=lambda x:-x[1])]\n",
    "    vocab_to_idx = {vocab:idx for idx, vocab in enumerate(idx_to_vocab)}\n",
    "    return idx_to_vocab, vocab_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cooccurrence(tokens, vocab_to_idx, window=2, min_cooccurrence=2):\n",
    "    counter = defaultdict(int)\n",
    "    for s, tokens_i in enumerate(tokens):\n",
    "        vocabs = [vocab_to_idx[w] for w in tokens_i if w in vocab_to_idx]\n",
    "        n = len(vocabs)\n",
    "        for i, v in enumerate(vocabs):\n",
    "            if window <= 0:\n",
    "                b, e = 0, n\n",
    "            else:\n",
    "                b = max(0, i - window)\n",
    "                e = min(i + window, n)\n",
    "            for j in range(b, e):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                counter[(v, vocabs[j])] += 1\n",
    "                counter[(vocabs[j], v)] += 1\n",
    "    counter = {k:v for k,v in counter.items() if v >= min_cooccurrence}\n",
    "    n_vocabs = len(vocab_to_idx)\n",
    "    return dict_to_mat(counter, n_vocabs, n_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_mat(d, n_rows, n_cols):\n",
    "    rows, cols, data = [], [], []\n",
    "    for (i, j), v in d.items():\n",
    "        rows.append(i)\n",
    "        cols.append(j)\n",
    "        data.append(v)\n",
    "    return csr_matrix((data, (rows, cols)), shape=(n_rows, n_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_graph(sents, tokenize=None, min_count=2, window=2, min_cooccurrence=2):\n",
    "    idx_to_vocab, vocab_to_idx = scan_vocabulary(sents, tokenize, min_count)\n",
    "    tokens = [tokenize(sent) for sent in sents]\n",
    "    g = cooccurrence(tokens, vocab_to_idx, window, min_cooccurrence, verbose)\n",
    "    return g, idx_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각각 요소들 한번 프린트 해봐\n",
    "\n",
    "def pagerank(x, df=0.85, max_iter=30):\n",
    "    assert 0 < df < 1\n",
    "\n",
    "    # initialize\n",
    "    A = normalize(x, axis=0, norm='l1')\n",
    "    R = np.ones(A.shape[0]).reshape(-1,1)\n",
    "    bias = (1 - df) * np.ones(A.shape[0]).reshape(-1,1)\n",
    "\n",
    "    # iteration\n",
    "    for _ in range(max_iter):\n",
    "        R = df * (A * R) + bias\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_keyword(sents, tokenize, min_count, window, min_cooccurrence, df=0.85, max_iter=30, topk=30):\n",
    "    g, idx_to_vocab = word_graph(sents, tokenize, min_count, window, min_cooccurrence)\n",
    "    R = pagerank(g, df, max_iter).reshape(-1)\n",
    "    idxs = R.argsort()[-topk:]\n",
    "    keywords = [(idx_to_vocab[idx], R[idx]) for idx in reversed(idxs)]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 핵심 문자 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_graph(sents, tokenize, similarity, min_count=2, min_sim=0.3):\n",
    "    _, vocab_to_idx = scan_vocabulary(sents, tokenize, min_count)\n",
    "\n",
    "    tokens = [[w for w in tokenize(sent) if w in vocab_to_idx] for sent in sents]\n",
    "    rows, cols, data = [], [], []\n",
    "    n_sents = len(tokens)\n",
    "    for i, tokens_i in enumerate(tokens):\n",
    "        for j, tokens_j in enumerate(tokens):\n",
    "            if i >= j:\n",
    "                continue\n",
    "#             print(tokens_i, tokens_j)\n",
    "            sim = similarity(tokens_i, tokens_j)\n",
    "#             print(sim)\n",
    "            if sim < min_sim:\n",
    "                continue\n",
    "            rows.append(i)\n",
    "            cols.append(j)\n",
    "            data.append(sim)\n",
    "    return csr_matrix((data, (rows, cols)), shape=(n_sents, n_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_sent_sim(s1, s2):\n",
    "    n1 = len(s1)\n",
    "    n2 = len(s2)\n",
    "    if (n1 <= 1) or (n2 <= 1):\n",
    "        return 0\n",
    "    common = len(set(s1).intersection(set(s2)))\n",
    "    base = math.log(n1) + math.log(n2)\n",
    "    return common / base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sent_sim(s1, s2):\n",
    "    if (not s1) or (not s2):\n",
    "        return 0\n",
    "\n",
    "    s1 = Counter(s1)\n",
    "    s2 = Counter(s2)\n",
    "    norm1 = math.sqrt(sum(v ** 2 for v in s1.values()))\n",
    "    norm2 = math.sqrt(sum(v ** 2 for v in s2.values()))\n",
    "    prod = 0\n",
    "    for k, v in s1.items():\n",
    "        prod += v * s2.get(k, 0)\n",
    "    return prod / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_keysentence(sents, tokenize, min_count, min_sim, similarity, df=0.85, max_iter=30, topk=5):\n",
    "    g = sent_graph(sents, tokenize,  similarity ,min_count, min_sim )\n",
    "    R = pagerank(g, df, max_iter).reshape(-1)\n",
    "    idxs = R.argsort()[-topk:]\n",
    "    keysents = [(idx, R[idx], sents[idx]) for idx in reversed(idxs)]\n",
    "    return keysents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "def komoran_tokenize(sent):\n",
    "    words = komoran.pos(sent, join=True)\n",
    "    words = [w for w in words if ('/NN' in w or '/XR' in w or '/VA' in w or '/VV' in w)]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.0360380811531846, '당진시 문화관광과를 대상으로 하는 행정사무감사에서 당진시립합창단 관계자가 보낸 것으로 추정되는 문자와 관련해 당진시의회가 행정사무조사특별위원회를 구성해 조사하겠다고 밝혔다.'), (1, 0.5993016407218469, '당진시의회 행정사무감사 3일차였던 지난 6일 문화관광과를 대상으로 하는 행감에서 최창용 의원은 “(당진시립합창단 정기연주회를 앞두고) 문자메세지를 제보받았다”며 “(음향팀에 보낸 것으로 추정되는) 해당 문자에는 ‘합창단이 소리를 작게 낼 것이니 알고 있으라’는 내용이었다”고 말했다.'), (3, 0.2956268584037232, '문제의 문자메세지를 전달받은 문화관광과는 감사법무담당관에게 조사를 의뢰했다.'), (2, 0.23871152005236096, '이어 “공연에서 소리를 작게 낸다는 것은 합창단으로서 그 임무를 하지 않겠다는 것”이며 “공연 자체를 무력화해 당진시를 망신 주려는 행위”라며 해당 문자를 보낸 단원 등 연루된 사람들을 찾아 사실관계를 확인하고 징계 등 책임을 물어야 한다고 지적했다.'), (4, 0.2242667024868477, '권경선 문화관광과장은 “누가, 어떻게 해서 해당 문자가 나온 것인지 정확히 조사해봐야 알 수 있다”며 “전달받은 문자 내용도 최 의원이 언급한 부분만 있어, 중간 내용만을 가지고는 전체를 유추할 수 없다”고 전했다.')]\n",
      "**********\n",
      "[(1, 1.2313885469477222, 'LA 에인절스의 최지만은 맹활약으로 주전 입지를 굳혀가는 반면 텍사스 레인저스의 추신수는 개막전 선발에서 밀려나는 수모를 당한 뒤에서도 좀처럼 반등을 하지 못하고 있다.'), (2, 1.0839850553071608, '최지만은 2일(한국시간) 미국 플로리다주 세인트피터즈버그 트로피카나 필드에서 열린 2019 미국프로야구 메이저리그 콜로라도 로키스와 홈경기에 3번 타자 1루수로 선발 출전해 4타수 2안타를 치고 1득점을 올렸다.'), (0, 0.986458826931048, '미국 메이저리그(MLB)에서 활동하는 한국 선수들의 시즌 초반 희비가 엇갈리고 있다.'), (7, 0.44648654181487457, '추신수는 들쭉날쭉한 출전 일정 탓인지 타격감을 찾지 못하고 있다.'), (3, 0.4390878602029615, '시즌 타율은 0.250에서 0.313(16타수 5안타)로 올랐다.')]\n",
      "**********\n",
      "[(0, 1.2436270040280082, '인천 부영공원 운영 생활야구협회 80여 동호회 팀에 260만 원씩 받아'), (2, 0.7567323382251988, '인천시 부평구 산곡동 부영공원 야구장을 운영하는 구 생활체육야구협회를 두고 특혜 논란이 불거지고 있다.'), (6, 0.6625110829854225, '16일 부평구와 협회 등에 따르면 부영공원 안에 있는 야구장을 구생활체육야구협회가 무상 사용하면서 이곳을 이용하는 야구동호회(80여 개 팀)로부터 팀별로 연간 260만 원씩 회비를 받고 있다.'), (1, 0.5678639912388261, '국유지로 임대료 없고 區서 지원도 일부 \"사용 내역 공개 등 폐쇄적\"'), (5, 0.4774519452018678, '인천시 부평구생활체육야구협회가 깜깜이로 부영공원을 운영하고 있다는 지적이 나오고 있다.')]\n",
      "**********\n",
      "[(0, 1.056243698118485, '대구·경북첨단의료산업진흥재단 의약생산센터는 항암주사제 무균충전 시설을 갖추고 있다.'), (1, 0.6516541958715495, '대구·경북첨단의료산업진흥재단(이하 대구첨복재단) 의약생산센터는 주세제 특수제제인 세포독성항암주사제제 품질관리기준(GMP)을 인증받았다고 31일 밝혔다.'), (3, 0.5001415516122023, '올해는 내용고형제와 원료의약품의 GMP 적합 여부 갱신 확인을 지난 4월 받은 데 이어 주사제 특수제제 생산시설 GMP 적합 여부 평가 승인을 지난 19일 받았다.'), (2, 0.426680392505328, '의약생산센터는 2016년 완제의약품, 2017년 원료 의약품에 대해 GMP 적합 승인을 받았다.'), (4, 0.29859097735687234, '세포독성항암제제는 약사법 시행규칙에서 정한 바에 따라 전용의 분리된 생산시설에서 생산돼야 한다.')]\n",
      "**********\n",
      "[(0, 0.9836563291119023, '국내 유통되는 탄산음료 중 식품의약품안전처에 품질인증을 받은 제품이 하나도 없는 것으로 나타났다.'), (2, 0.6394235617688114, '식품의약품안전처는 29일 여름철 어린이가 즐겨 마시는 탄산음료 282개와 혼합음료 350개를 대상으로 영양성분을 조사한 결과 품질인증을 받은 제품은 혼합음료 11개로, 탄산음료 중에는 없었다고 밝혔다.'), (1, 0.4996960052506598, '혼합음료 가운데는 3.1%에 불과했다.'), (3, 0.41804326760550375, '전체 탄산음료와 혼합음료 중 고열량·저영양 식품(이하 고·저 식품)은 절반에 가까운 274개(43.3%)로 확인됐다.'), (5, 0.2982136820963067, '탄산음료 고·저 식품의 당류 평균 함량은 1회 섭취참고량당(음료류 200ml) 22.5g(수입 21.5g, 국내제조 23.2g)으로 나타났고, 혼합음료의 경우 22.7g(수입 22.8g, 국내제조 22.6g)이었다.')]\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "df['article_original'][0]\n",
    "for i in range(5):\n",
    "    news_li = df['article_original'][i].split('\\n')\n",
    "    key_sents = textrank_keysentence(news_li, komoran_tokenize ,min_count= 2, min_sim = 0.3, similarity = textrank_sent_sim )\n",
    "    print(key_sents)\n",
    "    print('*'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
